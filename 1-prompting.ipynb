{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-1-prompting.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"cellView":"form","id":"5u5OZ2ShA3BA","jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T04:03:44.351842Z","iopub.execute_input":"2024-11-12T04:03:44.352275Z","iopub.status.idle":"2024-11-12T04:03:44.357606Z","shell.execute_reply.started":"2024-11-12T04:03:44.352236Z","shell.execute_reply":"2024-11-12T04:03:44.356191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install -U -q \"google-generativeai>=0.8.3\"","metadata":{"id":"NzwzJFU9LqkJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:22:43.744229Z","iopub.execute_input":"2024-11-12T20:22:43.744680Z","iopub.status.idle":"2024-11-12T20:23:14.806659Z","shell.execute_reply.started":"2024-11-12T20:22:43.744620Z","shell.execute_reply":"2024-11-12T20:23:14.805168Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import google.generativeai as genai\nfrom IPython.display import HTML, Markdown, display","metadata":{"id":"5DwxYIRavMST","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:23:28.146968Z","iopub.execute_input":"2024-11-12T20:23:28.148507Z","iopub.status.idle":"2024-11-12T20:23:29.428334Z","shell.execute_reply.started":"2024-11-12T20:23:28.148418Z","shell.execute_reply":"2024-11-12T20:23:29.427138Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"id":"SHl0bkPCvayd","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:23:38.460835Z","iopub.execute_input":"2024-11-12T20:23:38.461788Z","iopub.status.idle":"2024-11-12T20:23:38.676515Z","shell.execute_reply.started":"2024-11-12T20:23:38.461729Z","shell.execute_reply":"2024-11-12T20:23:38.675580Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"flash = genai.GenerativeModel('gemini-1.5-flash')\nresponse = flash.generate_content(\"Explain AI to me like I'm a kid.\")\nprint(response.text)","metadata":{"id":"BV1o0PmcvyJF","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:23:45.988825Z","iopub.execute_input":"2024-11-12T20:23:45.989393Z","iopub.status.idle":"2024-11-12T20:23:47.936646Z","shell.execute_reply.started":"2024-11-12T20:23:45.989339Z","shell.execute_reply":"2024-11-12T20:23:47.935508Z"}},"outputs":[{"name":"stdout","text":"Imagine you have a really smart robot friend who can learn new things! That's what AI, or Artificial Intelligence, is like. It's a special kind of computer program that can think and learn just like we do, but much faster.\n\nThink about how you learn to play a game. You try different things, see what works, and remember it for next time. AI is kind of like that, but with computers! It can:\n\n* **Recognize pictures:** Like when you show your robot friend a photo of a cat and it knows it's a cat, not a dog.\n* **Understand speech:** Your robot friend can listen to you talk and understand what you're saying.\n* **Play games:** It can learn how to play games, like chess or video games, and get really good at it!\n* **Write stories:** Your robot friend could even write you a cool story!\n\nAI is still learning, but it's getting smarter all the time. It's helping us do amazing things, like:\n\n* **Make self-driving cars:** Imagine cars that can drive themselves!\n* **Help doctors diagnose illnesses:** AI can help doctors find problems faster and easier.\n* **Make cool new robots:** Robots that can help us with chores or even be our friends!\n\nSo, AI is like a super smart robot friend who can learn and help us in lots of cool ways! ðŸ¤–ðŸ§ âœ¨ \n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"Markdown(response.text)","metadata":{"id":"c933e5e460a5","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:23:57.346617Z","iopub.execute_input":"2024-11-12T20:23:57.347047Z","iopub.status.idle":"2024-11-12T20:23:57.356552Z","shell.execute_reply.started":"2024-11-12T20:23:57.347006Z","shell.execute_reply":"2024-11-12T20:23:57.355299Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Imagine you have a really smart robot friend who can learn new things! That's what AI, or Artificial Intelligence, is like. It's a special kind of computer program that can think and learn just like we do, but much faster.\n\nThink about how you learn to play a game. You try different things, see what works, and remember it for next time. AI is kind of like that, but with computers! It can:\n\n* **Recognize pictures:** Like when you show your robot friend a photo of a cat and it knows it's a cat, not a dog.\n* **Understand speech:** Your robot friend can listen to you talk and understand what you're saying.\n* **Play games:** It can learn how to play games, like chess or video games, and get really good at it!\n* **Write stories:** Your robot friend could even write you a cool story!\n\nAI is still learning, but it's getting smarter all the time. It's helping us do amazing things, like:\n\n* **Make self-driving cars:** Imagine cars that can drive themselves!\n* **Help doctors diagnose illnesses:** AI can help doctors find problems faster and easier.\n* **Make cool new robots:** Robots that can help us with chores or even be our friends!\n\nSo, AI is like a super smart robot friend who can learn and help us in lots of cool ways! ðŸ¤–ðŸ§ âœ¨ \n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"chat = flash.start_chat(history=[])\nresponse = chat.send_message('Hello! My name is ABE.')\nprint(response.text)","metadata":{"id":"lV_S5ZL5MidD","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:24:10.505511Z","iopub.execute_input":"2024-11-12T20:24:10.505997Z","iopub.status.idle":"2024-11-12T20:24:11.005696Z","shell.execute_reply.started":"2024-11-12T20:24:10.505955Z","shell.execute_reply":"2024-11-12T20:24:11.004313Z"}},"outputs":[{"name":"stdout","text":"Hello ABE! It's nice to meet you. ðŸ˜Š  What can I do for you today? \n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"response = chat.send_message('Can you tell something interesting about dinosaurs?')\nprint(response.text)","metadata":{"id":"7b0372c3c64a","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:24:17.023305Z","iopub.execute_input":"2024-11-12T20:24:17.023752Z","iopub.status.idle":"2024-11-12T20:24:18.829517Z","shell.execute_reply.started":"2024-11-12T20:24:17.023706Z","shell.execute_reply":"2024-11-12T20:24:18.828300Z"}},"outputs":[{"name":"stdout","text":"Okay, here's a fascinating fact about dinosaurs:\n\n**Some dinosaurs had feathers!** \n\nThis might surprise you, but many dinosaurs, especially the smaller, bird-like ones, had feathers. These feathers weren't just for show; they were used for insulation, display, and even flight in some species.  Scientists have found fossils with clear evidence of feathers, helping us understand the evolution of birds from dinosaurs. \n\nWhat else would you like to know about dinosaurs? ðŸ¦– \n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# While you have the `chat` object around, the conversation state\n# persists. Confirm that by asking if it knows my name.\nresponse = chat.send_message('Do you remember what my name is?')\nprint(response.text)","metadata":{"id":"d3f9591392a7","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:24:35.706774Z","iopub.execute_input":"2024-11-12T20:24:35.707215Z","iopub.status.idle":"2024-11-12T20:24:39.303105Z","shell.execute_reply.started":"2024-11-12T20:24:35.707174Z","shell.execute_reply":"2024-11-12T20:24:39.301866Z"}},"outputs":[{"name":"stdout","text":"Of course I remember! Your name is ABE. ðŸ˜Š I'm always happy to see you again. \n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for model in genai.list_models():\n  print(model.name)","metadata":{"id":"uUUZa2uq2jDm","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:24:43.818489Z","iopub.execute_input":"2024-11-12T20:24:43.818947Z","iopub.status.idle":"2024-11-12T20:24:43.996862Z","shell.execute_reply.started":"2024-11-12T20:24:43.818902Z","shell.execute_reply":"2024-11-12T20:24:43.995691Z"}},"outputs":[{"name":"stdout","text":"models/chat-bison-001\nmodels/text-bison-001\nmodels/embedding-gecko-001\nmodels/gemini-1.0-pro-latest\nmodels/gemini-1.0-pro\nmodels/gemini-pro\nmodels/gemini-1.0-pro-001\nmodels/gemini-1.0-pro-vision-latest\nmodels/gemini-pro-vision\nmodels/gemini-1.5-pro-latest\nmodels/gemini-1.5-pro-001\nmodels/gemini-1.5-pro-002\nmodels/gemini-1.5-pro\nmodels/gemini-1.5-pro-exp-0801\nmodels/gemini-1.5-pro-exp-0827\nmodels/gemini-1.5-flash-latest\nmodels/gemini-1.5-flash-001\nmodels/gemini-1.5-flash-001-tuning\nmodels/gemini-1.5-flash\nmodels/gemini-1.5-flash-exp-0827\nmodels/gemini-1.5-flash-002\nmodels/gemini-1.5-flash-8b\nmodels/gemini-1.5-flash-8b-001\nmodels/gemini-1.5-flash-8b-latest\nmodels/gemini-1.5-flash-8b-exp-0827\nmodels/gemini-1.5-flash-8b-exp-0924\nmodels/embedding-001\nmodels/text-embedding-004\nmodels/aqa\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"for model in genai.list_models():\n  if model.name == 'models/gemini-1.5-flash':\n    print(model)\n    break","metadata":{"id":"k7JJ1K6j4Rl8","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:24:49.898672Z","iopub.execute_input":"2024-11-12T20:24:49.899167Z","iopub.status.idle":"2024-11-12T20:24:50.052142Z","shell.execute_reply.started":"2024-11-12T20:24:49.899124Z","shell.execute_reply":"2024-11-12T20:24:50.050944Z"}},"outputs":[{"name":"stdout","text":"Model(name='models/gemini-1.5-flash',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Flash',\n      description='Fast and versatile multimodal model for scaling across diverse tasks',\n      input_token_limit=1000000,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=40)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"short_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(max_output_tokens=200))\n\nresponse = short_model.generate_content('Write a 1000 word essay on the importance of olives in modern society.')\nprint(response.text)","metadata":{"id":"qVf23JsIi9ma","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:25:11.546861Z","iopub.execute_input":"2024-11-12T20:25:11.547325Z","iopub.status.idle":"2024-11-12T20:25:13.343660Z","shell.execute_reply.started":"2024-11-12T20:25:11.547282Z","shell.execute_reply":"2024-11-12T20:25:13.342324Z"}},"outputs":[{"name":"stdout","text":"## The Enduring Importance of Olives in Modern Society\n\nFrom ancient olive groves that graced the Mediterranean to contemporary urban landscapes, the olive tree stands as a testament to resilience and cultural significance. More than just a source of delicious fruit, olives hold a profound importance in modern society, weaving through our culinary habits, economic structures, and even our cultural identity.\n\n**A Culinary Staple and a Symphony of Flavors:**\n\nOlive oil, the liquid gold extracted from the fruit, reigns supreme in kitchens across the globe. Its versatility is unparalleled, seamlessly transitioning from delicate drizzle on salads to the foundation of rich, savory sauces. Its distinct flavor profile, ranging from grassy and peppery to fruity and buttery, enhances dishes with an unparalleled depth. Beyond oil, olives themselves, whether green, black, or briny, offer a textural contrast and savory punch that enriches salads, pizzas, and tapas.\n\nThe impact of olives on modern cuisine is profound. They are an integral part of Mediterranean diets, lauded\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"response = short_model.generate_content('Write a short poem on the importance of olives in modern society.')\nprint(response.text)","metadata":{"id":"W-3kR2F5kdMR","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:25:20.948754Z","iopub.execute_input":"2024-11-12T20:25:20.949178Z","iopub.status.idle":"2024-11-12T20:25:21.850313Z","shell.execute_reply.started":"2024-11-12T20:25:20.949139Z","shell.execute_reply":"2024-11-12T20:25:21.848865Z"}},"outputs":[{"name":"stdout","text":"From ancient groves, a bounty bright,\nThe olive's fruit, a savory light.\nA drop of oil, a savory grace,\nOn plates we share, in every place.\n\nFrom salads green to savory bread,\nIt seasons life, both rich and spread.\nA symbol strong, of peace and grace,\nThe olive's gift, in every space.\n\nSo let us raise a glass, to say,\nFor olives, thank you, every day.\nA gift of nature, pure and true,\nAn ancient fruit, forever new. \n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from google.api_core import retry\n\nhigh_temp_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(temperature=2.0))\n\n\n# When running lots of queries, it's a good practice to use a retry policy so your code\n# automatically retries when hitting Resource Exhausted (quota limit) errors.\nretry_policy = {\n    \"retry\": retry.Retry(predicate=retry.if_transient_error, initial=10, multiplier=1.5, timeout=300)\n}\n\nfor _ in range(5):\n  response = high_temp_model.generate_content('Pick a random colour... (respond in a single word)',\n                                              request_options=retry_policy)\n  if response.parts:\n    print(response.text, '-' * 25)","metadata":{"id":"SHraGMzqnZqt","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:25:28.818743Z","iopub.execute_input":"2024-11-12T20:25:28.819186Z","iopub.status.idle":"2024-11-12T20:25:30.539064Z","shell.execute_reply.started":"2024-11-12T20:25:28.819142Z","shell.execute_reply":"2024-11-12T20:25:30.537819Z"}},"outputs":[{"name":"stdout","text":"Purple. \n -------------------------\nIndigo \n -------------------------\nBlue \n -------------------------\nBlue \n -------------------------\nPurple \n -------------------------\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"low_temp_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(temperature=0.0))\n\nfor _ in range(5):\n  response = low_temp_model.generate_content('Pick a random colour... (respond in a single word)',\n                                             request_options=retry_policy)\n  if response.parts:\n    print(response.text, '-' * 25)","metadata":{"id":"clymkWv-PfUZ","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:25:35.978003Z","iopub.execute_input":"2024-11-12T20:25:35.978426Z","iopub.status.idle":"2024-11-12T20:25:37.700672Z","shell.execute_reply.started":"2024-11-12T20:25:35.978385Z","shell.execute_reply":"2024-11-12T20:25:37.699459Z"}},"outputs":[{"name":"stdout","text":"Purple \n -------------------------\nPurple \n -------------------------\nPurple \n -------------------------\nPurple \n -------------------------\nPurple \n -------------------------\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        # These are the default values for gemini-1.5-flash-001.\n        temperature=1.0,\n        top_k=64,\n        top_p=0.95,\n    ))\n\nstory_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\nresponse = model.generate_content(story_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"id":"lPlzpEavUV8F","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:25:46.430470Z","iopub.execute_input":"2024-11-12T20:25:46.430934Z","iopub.status.idle":"2024-11-12T20:25:49.788086Z","shell.execute_reply.started":"2024-11-12T20:25:46.430889Z","shell.execute_reply":"2024-11-12T20:25:49.786766Z"}},"outputs":[{"name":"stdout","text":"Barnaby wasn't your average tabby. While his brethren were content with napping in sunbeams and chasing dust motes, Barnaby yearned for adventure. He dreamt of exotic lands, towering trees, and the thrill of the unknown. \n\nOne day, a delivery truck rumbled down the street, its back doors swinging open to reveal a mountain of cardboard boxes. Barnaby's heart leaped. This was his chance! As the delivery man struggled with a particularly heavy box, Barnaby saw his opportunity. He slipped through a gap, landing soundlessly in the cavernous space. He sniffed the air, the scent of adventure swirling around him.\n\nThe truck jolted, its engine roaring, and Barnaby was thrown into the darkness. He squeezed his eyes shut, bracing himself for the worst. But the worst never came. Instead, he was met with a gentle sway, a comforting darkness that smelled ofâ€¦strawberries?\n\nWhen the truck finally stopped, Barnaby cautiously emerged. He found himself in a bustling marketplace, the air thick with the scent of spices and fresh produce. A woman, her hair a vibrant shade of turquoise, offered him a juicy piece of melon, her eyes sparkling with amusement. He devoured it, the sweet juice exploding on his tongue.\n\nBarnaby spent the next few days exploring this fantastical world. He rode on the back of a donkey, its furry coat soft beneath his paws. He chased butterflies with shimmering wings, each a rainbow in flight. He learned to barter for fish with a grumpy old man who spoke in clicks and whistles.\n\nHe even found a new friend, a mischievous little monkey named Coco, who loved to swing from the trees and share juicy mangoes with him. Together, they explored the hidden corners of the jungle, their laughter echoing through the dense foliage.\n\nBut as the sun began to set on Barnaby's adventure, a pang of longing hit him. He missed his warm bed, the familiar scent of his human, and the comforting routine of his life. He knew it was time to go home.\n\nHe found the delivery truck, its back doors open once again. He slipped inside, a sense of contentment washing over him. As the truck rumbled back down the street, Barnaby closed his eyes, the world fading into a blur of colors and smells. \n\nHe returned home a changed cat. Though he still enjoyed his naps and dust motes, Barnaby now carried a secret within him - a memory of adventure, a taste of the exotic, and a twinkle in his eye that spoke of a world beyond his own backyard. And every now and then, he would sneak a peek at the world outside his window, knowing that adventure was always just a cardboard box away. \n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        top_p=1,\n        max_output_tokens=5,\n    ))\n\nzero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\nReview: \"Her\" is a disturbing study revealing the direction\nhumanity is headed if AI is allowed to keep evolving,\nunchecked. I wish there were more movies like this masterpiece.\nSentiment: \"\"\"\n\nresponse = model.generate_content(zero_shot_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"id":"1_t-cwnDZzbH","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:26:16.180835Z","iopub.execute_input":"2024-11-12T20:26:16.181316Z","iopub.status.idle":"2024-11-12T20:26:16.514748Z","shell.execute_reply.started":"2024-11-12T20:26:16.181275Z","shell.execute_reply":"2024-11-12T20:26:16.513419Z"}},"outputs":[{"name":"stdout","text":"Sentiment: **POSITIVE**\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import enum\n\nclass Sentiment(enum.Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL = \"neutral\"\n    NEGATIVE = \"negative\"\n\n\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        response_mime_type=\"text/x.enum\",\n        response_schema=Sentiment\n    ))\n\nresponse = model.generate_content(zero_shot_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"id":"ad118a56c598","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:26:33.268498Z","iopub.execute_input":"2024-11-12T20:26:33.268952Z","iopub.status.idle":"2024-11-12T20:26:33.779964Z","shell.execute_reply.started":"2024-11-12T20:26:33.268908Z","shell.execute_reply":"2024-11-12T20:26:33.778548Z"}},"outputs":[{"name":"stdout","text":"positive\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        top_p=1,\n        max_output_tokens=250,\n    ))\n\nfew_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n\nEXAMPLE:\nI want a small pizza with cheese, tomato sauce, and pepperoni.\nJSON Response:\n```\n{\n\"size\": \"small\",\n\"type\": \"normal\",\n\"ingredients\": [\"cheese\", \"tomato sauce\", \"peperoni\"]\n}\n```\n\nEXAMPLE:\nCan I get a large pizza with tomato sauce, basil and mozzarella\nJSON Response:\n```\n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n}\n\nORDER:\n\"\"\"\n\ncustomer_order = \"Give me a large with cheese & pineapple\"\n\n\nresponse = model.generate_content([few_shot_prompt, customer_order], request_options=retry_policy)\nprint(response.text)","metadata":{"id":"hd4mVUukwOKZ","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:26:49.971552Z","iopub.execute_input":"2024-11-12T20:26:49.972091Z","iopub.status.idle":"2024-11-12T20:26:50.415384Z","shell.execute_reply.started":"2024-11-12T20:26:49.972042Z","shell.execute_reply":"2024-11-12T20:26:50.412954Z"}},"outputs":[{"name":"stdout","text":"```json\n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [\"cheese\", \"pineapple\"]\n}\n``` \n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import typing_extensions as typing\n\nclass PizzaOrder(typing.TypedDict):\n    size: str\n    ingredients: list[str]\n    type: str\n\n\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        response_mime_type=\"application/json\",\n        response_schema=PizzaOrder,\n    ))\n\nresponse = model.generate_content(\"Can I have a large dessert pizza with apple and chocolate\")\nprint(response.text)","metadata":{"id":"50fbf0260912","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:27:04.667385Z","iopub.execute_input":"2024-11-12T20:27:04.667898Z","iopub.status.idle":"2024-11-12T20:27:05.143456Z","shell.execute_reply.started":"2024-11-12T20:27:04.667850Z","shell.execute_reply":"2024-11-12T20:27:05.141565Z"}},"outputs":[{"name":"stdout","text":"{\"ingredients\": [\"apple\", \"chocolate\"], \"size\": \"large\", \"type\": \"dessert\"}\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now, I\nam 20 years old. How old is my partner? Return the answer immediately.\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nresponse = model.generate_content(prompt, request_options=retry_policy)\n\nprint(response.text)","metadata":{"id":"5715555db1c1","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:27:26.139353Z","iopub.execute_input":"2024-11-12T20:27:26.139836Z","iopub.status.idle":"2024-11-12T20:27:26.785315Z","shell.execute_reply.started":"2024-11-12T20:27:26.139789Z","shell.execute_reply":"2024-11-12T20:27:26.783723Z"}},"outputs":[{"name":"stdout","text":"52 \n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now,\nI am 20 years old. How old is my partner? Let's think step by step.\"\"\"\n\nresponse = model.generate_content(prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"id":"ffd7536a481f","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:27:33.538973Z","iopub.execute_input":"2024-11-12T20:27:33.539710Z","iopub.status.idle":"2024-11-12T20:27:34.290531Z","shell.execute_reply.started":"2024-11-12T20:27:33.539650Z","shell.execute_reply":"2024-11-12T20:27:34.289108Z"}},"outputs":[{"name":"stdout","text":"Here's how to solve this:\n\n* **When you were 4:** Your partner was 3 times your age, so they were 4 * 3 = 12 years old.\n* **Age difference:** This means your partner is 12 - 4 = 8 years older than you.\n* **Current age:** Since you are now 20, your partner is 20 + 8 = **28 years old**. \n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"model_instructions = \"\"\"\nSolve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation,\nObservation is understanding relevant information from an Action's output and Action can be one of three types:\n (1) <search>entity</search>, which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it\n     will return some similar entities to search and you can try to search the information from those topics.\n (2) <lookup>keyword</lookup>, which returns the next sentence containing keyword in the current context. This only does exact matches,\n     so keep your searches short.\n (3) <finish>answer</finish>, which returns the answer and finishes the task.\n\"\"\"\n\nexample1 = \"\"\"Question\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n\nThought 1\nThe question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n\nAction 1\n<search>Milhouse</search>\n\nObservation 1\nMilhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n\nThought 2\nThe paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n\nAction 2\n<lookup>named after</lookup>\n\nObservation 2\nMilhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n\nThought 3\nMilhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n\nAction 3\n<finish>Richard Nixon</finish>\n\"\"\"\n\nexample2 = \"\"\"Question\nWhat is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n\nThought 1\nI need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n\nAction 1\n<search>Colorado orogeny</search>\n\nObservation 1\nThe Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n\nThought 2\nIt does not mention the eastern sector. So I need to look up eastern sector.\n\nAction 2\n<lookup>eastern sector</lookup>\n\nObservation 2\nThe eastern sector extends into the High Plains and is called the Central Plains orogeny.\n\nThought 3\nThe eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n\nAction 3\n<search>High Plains</search>\n\nObservation 3\nHigh Plains refers to one of two distinct land regions\n\nThought 4\nI need to instead search High Plains (United States).\n\nAction 4\n<search>High Plains (United States)</search>\n\nObservation 4\nThe High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130m).\n\nThought 5\nHigh Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n\nAction 5\n<finish>1,800 to 7,000 ft</finish>\n\"\"\"\n\n# Come up with more examples yourself, or take a look through https://github.com/ysymyth/ReAct/","metadata":{"id":"cBgyNJ5z0VSs","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:28:00.957636Z","iopub.execute_input":"2024-11-12T20:28:00.958244Z","iopub.status.idle":"2024-11-12T20:28:00.969192Z","shell.execute_reply.started":"2024-11-12T20:28:00.958192Z","shell.execute_reply":"2024-11-12T20:28:00.967507Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"question = \"\"\"Question\nWho was the youngest author listed on the transformers NLP paper?\n\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nreact_chat = model.start_chat()\n\n# You will perform the Action, so generate up to, but not including, the Observation.\nconfig = genai.GenerationConfig(stop_sequences=[\"\\nObservation\"])\n\nresp = react_chat.send_message(\n    [model_instructions, example1, example2, question],\n    generation_config=config,\n    request_options=retry_policy)\nprint(resp.text)","metadata":{"id":"8mxrXRkRTdXm","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:28:08.345410Z","iopub.execute_input":"2024-11-12T20:28:08.345971Z","iopub.status.idle":"2024-11-12T20:28:09.950056Z","shell.execute_reply.started":"2024-11-12T20:28:08.345922Z","shell.execute_reply":"2024-11-12T20:28:09.948728Z"}},"outputs":[{"name":"stdout","text":"Thought 1\nI need to search for the Transformers NLP paper and find the authors, then identify the youngest one.\n\nAction 1\n<search>Transformers NLP paper</search>\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"observation = \"\"\"Observation 1\n[1706.03762] Attention Is All You Need\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\nWe propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n\"\"\"\nresp = react_chat.send_message(observation, generation_config=config, request_options=retry_policy)\nprint(resp.text)","metadata":{"id":"mLMc0DZaV9g2","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:28:19.461125Z","iopub.execute_input":"2024-11-12T20:28:19.461843Z","iopub.status.idle":"2024-11-12T20:28:20.134708Z","shell.execute_reply.started":"2024-11-12T20:28:19.461779Z","shell.execute_reply":"2024-11-12T20:28:20.133533Z"}},"outputs":[{"name":"stdout","text":"Thought 2: The observation provides the authors of the Transformers NLP paper, but doesn't specify their ages. I need to find information about their ages.\n\nAction 2: <search>Ashish Vaswani age</search> \n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        temperature=1,\n        top_p=1,\n        max_output_tokens=1024,\n    ))\n\n# Gemini 1.5 models are very chatty, so it helps to specify they stick to the code.\ncode_prompt = \"\"\"\nWrite a Python function to calculate the factorial of a number. No explanation, provide only the code.\n\"\"\"\n\nresponse = model.generate_content(code_prompt, request_options=retry_policy)\nMarkdown(response.text)","metadata":{"id":"fOQP9pqmeUO1","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:28:30.828018Z","iopub.execute_input":"2024-11-12T20:28:30.828476Z","iopub.status.idle":"2024-11-12T20:28:31.337236Z","shell.execute_reply.started":"2024-11-12T20:28:30.828419Z","shell.execute_reply":"2024-11-12T20:28:31.336054Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```python\ndef factorial(n):\n  if n == 0:\n    return 1\n  else:\n    return n * factorial(n-1)\n```"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    tools='code_execution',)\n\ncode_exec_prompt = \"\"\"\nCalculate the sum of the first 14 prime numbers. Only consider the odd primes, and make sure you count them all.\n\"\"\"\n\nresponse = model.generate_content(code_exec_prompt, request_options=retry_policy)\nMarkdown(response.text)","metadata":{"id":"jT3OfWYfhjRL","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:28:43.211099Z","iopub.execute_input":"2024-11-12T20:28:43.211656Z","iopub.status.idle":"2024-11-12T20:28:47.556022Z","shell.execute_reply.started":"2024-11-12T20:28:43.211605Z","shell.execute_reply":"2024-11-12T20:28:47.554605Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n``` python\nimport sympy\n\nprimes = [x for x in sympy.primerange(1, 100) if x % 2 != 0]\nsum_primes = sum(primes[:14])\nprint(f'{sum_primes=}')\n\n```\n```\nsum_primes=326\n\n```\nI used sympy to generate a list of prime numbers between 1 and 100, filtering out the even numbers. Then I took the first 14 elements of the list and summed them. The result is 326. \n"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"for part in response.candidates[0].content.parts:\n  print(part)\n  print(\"-----\")","metadata":{"id":"j4gQVzcRjRX-","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:29:36.988685Z","iopub.execute_input":"2024-11-12T20:29:36.989707Z","iopub.status.idle":"2024-11-12T20:29:36.996490Z","shell.execute_reply.started":"2024-11-12T20:29:36.989657Z","shell.execute_reply":"2024-11-12T20:29:36.995288Z"}},"outputs":[{"name":"stdout","text":"text: \"\"\n\n-----\nexecutable_code {\n  language: PYTHON\n  code: \"\\nimport sympy\\n\\nprimes = [x for x in sympy.primerange(1, 100) if x % 2 != 0]\\nsum_primes = sum(primes[:14])\\nprint(f\\'{sum_primes=}\\')\\n\"\n}\n\n-----\ncode_execution_result {\n  outcome: OUTCOME_OK\n  output: \"sum_primes=326\\n\"\n}\n\n-----\ntext: \"I used sympy to generate a list of prime numbers between 1 and 100, filtering out the even numbers. Then I took the first 14 elements of the list and summed them. The result is 326. \\n\"\n\n-----\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"file_contents = !curl https://raw.githubusercontent.com/magicmonty/bash-git-prompt/refs/heads/master/gitprompt.sh\n\nexplain_prompt = f\"\"\"\nPlease explain what this file does at a very high level. What is it, and why would I use it?\n\n```\n{file_contents}\n```\n\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\n\nresponse = model.generate_content(explain_prompt, request_options=retry_policy)\nMarkdown(response.text)","metadata":{"id":"7_jPMMoxkIEb","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T20:30:02.553645Z","iopub.execute_input":"2024-11-12T20:30:02.554191Z","iopub.status.idle":"2024-11-12T20:30:05.988142Z","shell.execute_reply.started":"2024-11-12T20:30:02.554147Z","shell.execute_reply":"2024-11-12T20:30:05.986769Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"This file is a Bash script named `git-prompt.sh`.  It provides a custom Git prompt for your terminal, enhancing the default Bash prompt with information about the current Git repository.\n\n**Here's a breakdown of its core functionalities:**\n\n1. **Git Status Information:** The script fetches and displays crucial Git information like:\n    - **Current branch:** The name of the branch you're working on.\n    - **Upstream tracking:** Whether you're ahead, behind, or in sync with the remote branch.\n    - **Changes:** Indicates staged, unstaged, conflicted, untracked, stashed, and clean statuses.\n    - **Detached HEAD:** Identifies a detached HEAD state.\n\n2. **Customization:** You can customize the prompt appearance through:\n    - **Themes:** Select from available themes or create your custom theme to change colors and styling.\n    - **Symbols:** Set custom symbols for different Git states (e.g., ahead, behind).\n    - **Variables:** Configure various settings like leading spaces, displaying untracked files, and remote status.\n\n3. **Virtual Environment Integration:**  The script integrates with virtual environments like virtualenv, conda, and Node.js to display their active state in your prompt.\n\n4. **Installation:** \n    - The script adds its `setGitPrompt` function to your `PROMPT_COMMAND`. This function automatically updates your prompt when you navigate between directories or change your Git status.\n    - You'd typically source this script in your `~/.bashrc` or equivalent config file to enable it.\n\n**Why would you use it?**\n\n- **Enhanced Git Awareness:** This script makes you more aware of your Git status, allowing you to quickly understand:\n    - The branch you're on\n    - Whether there are changes you need to commit\n    - Whether you're ahead or behind the remote branch\n    - If there are any conflicts or untracked files\n\n- **Improved Efficiency:**  The script helps you navigate your Git workflow more efficiently by providing clear and concise information at a glance.\n\n- **Customization:** It offers extensive customization options to suit your personal preferences and development environment.\n\n**In essence, this script enhances your Bash terminal experience by integrating Git information directly into your prompt, providing a more informative and efficient development environment.** \n"},"metadata":{}}],"execution_count":28}]}